{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "\n",
    "In [chapter 5](https://learn.deeplearning.ai/courses/langchain/lesson/5/question-and-answer), the topic was \"Questions & Answers\".\n",
    "\n",
    "To re-work the lesson, I will first re-create that example presented in the lesson, without diving into too much detail, because I covered embedding in the under aligning theory in my blog posts [Visualizing Embeddings in 2D](https://chrwittm.github.io/posts/2024-03-15-embeddings/) and [Remembering the Wittmann Tours World Trip with RAG](https://chrwittm.github.io/posts/2024-03-22-rag1-remembering-world-trip/).\n",
    "\n",
    "Speaking about Wittmann Tours, I will re-create the mini RAG scenario using Lang chain afterwards as personal exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating the example from the lesson\n",
    "\n",
    "Here is the example CSV file used in this chapter, Let's take a quick look in a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the dataset are: ['Unnamed: 0', 'name', 'description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"OutdoorClothingCatalog_1000.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "print(f\"The columns of the dataset are: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Women's Campside Oxfords</td>\n",
       "      <td>This ultracomfortable lace-to-toe Oxford boast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Recycled Waterhog Dog Mat, Chevron Weave</td>\n",
       "      <td>Protect your floors from spills and splashing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Infant and Toddler Girls' Coastal Chill Swimsu...</td>\n",
       "      <td>She'll love the bright colors, ruffles and exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Refresh Swimwear, V-Neck Tankini Contrasts</td>\n",
       "      <td>Whether you're going for a swim or heading out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>EcoFlex 3L Storm Pants</td>\n",
       "      <td>Our new TEK O2 technology makes our four-seaso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               name  \\\n",
       "0           0                           Women's Campside Oxfords   \n",
       "1           1           Recycled Waterhog Dog Mat, Chevron Weave   \n",
       "2           2  Infant and Toddler Girls' Coastal Chill Swimsu...   \n",
       "3           3         Refresh Swimwear, V-Neck Tankini Contrasts   \n",
       "4           4                             EcoFlex 3L Storm Pants   \n",
       "\n",
       "                                         description  \n",
       "0  This ultracomfortable lace-to-toe Oxford boast...  \n",
       "1  Protect your floors from spills and splashing ...  \n",
       "2  She'll love the bright colors, ruffles and exc...  \n",
       "3  Whether you're going for a swim or heading out...  \n",
       "4  Our new TEK O2 technology makes our four-seaso...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we load the data with the langchain `CSVLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=': 0\n",
      "name: Women's Campside Oxfords\n",
      "description: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \n",
      "\n",
      "Size & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \n",
      "\n",
      "Specs: Approx. weight: 1 lb.1 oz. per pair. \n",
      "\n",
      "Construction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \n",
      "\n",
      "Questions? Please contact us for any inquiries.' metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "data = loader.load()\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() #contains the OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running this notebook for the first time, you might need to install `docarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings  # OpenAI embeddings model\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Create the index with the embedding model\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embedding  # Provide the required embedding model\n",
    ").from_loaders([loader])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we use `gpt-4o-mini` instead of `gpt-3.5-turbo-instruct`. The reason is simply that time has moved on, and there is no instruct variant of GPT-4o. As GPT-4o points out:\n",
    "\n",
    "_\"While GPT-4 chat models, like gpt-4o-mini, do not have a separate instruct variant, they are already trained to handle instruction-based tasks very effectively.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_response(response):\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a table listing the shirts with sun protection along with a summary of each:\n",
       "\n",
       "| Name                                      | Description Summary                                                                                     |\n",
       "|-------------------------------------------|--------------------------------------------------------------------------------------------------------|\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt   | Lightweight, UPF 50+ sun protection, 100% polyester, wrinkle-resistant, with cape venting and pockets. |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve    | UPF 50+ protection, made of 52% polyester and 48% nylon, wrinkle-free, evaporates perspiration, with cape venting and pockets. |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve      | UPF 50+ rated, lightweight, 71% nylon and 29% polyester, wrinkle resistant, with cape venting and pockets. |\n",
       "| Sun Shield Shirt                          | UPF 50+ rated, made of 78% nylon and 22% Lycra, moisture-wicking, abrasion resistant, fits over swimsuits. |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Please list all your shirts with sun protection in a table in markdown and summarize each one.\"\n",
    "response = index.query(query, llm = llm)\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wittmann-Tours\n",
    "\n",
    "Let's transition the example implementation to re-creating my manual implementation [Remembering the Wittmann Tours World Trip with RAG](https://chrwittm.github.io/posts/2024-03-22-rag1-remembering-world-trip/).\n",
    "\n",
    "The implementation idea is simple: Instead of indexing lines of a CSV file, let's index the markdown files of the Wittmann-Tours blog.\n",
    "\n",
    "Since we have already downloaded the dataset in chapter 2, here are just the helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def get_blog_post_files(path_to_blog):\n",
    "\n",
    "    pattern = os.path.join(path_to_blog, \"**/*.md\")\n",
    "    return sorted(glob.glob(pattern, recursive=True))\n",
    "\n",
    "def get_blogpost(path_to_blogpost):\n",
    "    with open(path_to_blogpost, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../wt-blogposts/3-tage-in-melbourne/index.md',\n",
       " './../wt-blogposts/addis-abeba-die-hauptstadt-athiopiens/index.md',\n",
       " './../wt-blogposts/aksum-aufbewahrungsort-der-bundeslade/index.md',\n",
       " './../wt-blogposts/am-fusse-des-cotopaxi/index.md',\n",
       " './../wt-blogposts/an-der-grenze-von-mexiko-nach-belize/index.md']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogpost_files = get_blog_post_files(\"./../wt-blogposts\")\n",
    "blogpost_files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this for the first time, you might need to install `unstructured`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a loader for each markdown file. All these loaders are stored in the `loaders` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loaders = [UnstructuredMarkdownLoader(blogpost_file) for blogpost_file in blogpost_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader at 0x336694ac0>,\n",
       " <langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader at 0x3366971c0>,\n",
       " <langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader at 0x3366972e0>,\n",
       " <langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader at 0x336696f20>,\n",
       " <langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader at 0x336697370>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turned out, what we are about to do, requires the `Punkt` tokenizer, a data package used by NLTK (Natural Language Toolkit) for sentence splitting.\n",
    "\n",
    "While implementing this prototype, I received a few weird error messages regarding the file locations of the punkt tokenizer. It turned out that you need to be on the latest punkt version (3.9.1). (My earlier version 3.8.1 caused the problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall nltk\n",
    "#!pip install nltk\n",
    "#!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chrwittm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we can index all the markdown files by loading them into the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embedding\n",
    ").from_loaders(loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to query the Wittmann tour blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Euer Guide im Masoala Regenwald hieß Armand."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#query = \"What was the name of our guide in the Masoala rain forest??\"\n",
    "query = \"Wie hieß unser Guide im Masoala Regenwald?\"\n",
    "response = index.query(query, llm = llm)\n",
    "\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turned out, I need to prompt the model in German to get the right result, because the Wittmann-Tours blog is written in German. Unlike the example that I created in my [previous blog post](https://chrwittm.github.io/posts/2024-03-22-rag1-remembering-world-trip/), this version is not multilingual. However, this could easily be fixed with other langchain functionality, as we've seen in previous chapters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
